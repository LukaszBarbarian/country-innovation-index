{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8712f741-f496-4d9a-ac16-f6c247fc88b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CV-DEMO1/azure_databricks/notebooks/00_init_paths.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Rozpoczynam inicjalizację środowiska Databricks dla monorepo 'CV-DEMO1'.\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# --- Krok 1: Określenie DOKŁADNEJ ścieżki do głównego katalogu repozytorium (CV-DEMO1) ---\n",
    "# Celem jest dodanie ścieżki do folderu 'CV-DEMO1' do sys.path.\n",
    "# Będziemy szukać tego fragmentu w ścieżce zwróconej przez dbutils.\n",
    "\n",
    "REPO_ROOT_DIR_NAME = 'CV-DEMO1' # Nazwa głównego katalogu repozytorium\n",
    "\n",
    "try:\n",
    "    # PREFEROWANA METODA DLA NOWSZYCH WERSJI DATABRICKS:\n",
    "    full_notebook_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "    print(f\"Pełna ścieżka bieżącego notebooka (dbutils): {full_notebook_path}\")\n",
    "\n",
    "    # Znajdź indeks, gdzie zaczyna się nazwa głównego repozytorium\n",
    "    idx = full_notebook_path.find(REPO_ROOT_DIR_NAME)\n",
    "    if idx != -1:\n",
    "        # Utnij ścieżkę, aby uzyskać sam katalog repozytorium\n",
    "        # Np. z '/Users/.../CV-DEMO1/azure_databricks/notebooks/my_notebook.py' -> '/Users/.../CV-DEMO1'\n",
    "        calculated_project_root_path = full_notebook_path[:idx + len(REPO_ROOT_DIR_NAME)]\n",
    "    else:\n",
    "        # Awaryjne rozwiązanie: jeśli nazwa repo nie została znaleziona w ścieżce dbutils,\n",
    "        # spróbuj z os.getcwd() i ręcznym cofaniem się.\n",
    "        print(f\"Ostrzeżenie: '{REPO_ROOT_DIR_NAME}' nie znaleziono w ścieżce notebooka. Próba użycia os.getcwd().\")\n",
    "        # Zakładamy, że os.getcwd() to .../azure_databricks/notebooks (lub common/notebooks)\n",
    "        # BARDZO WAŻNE: Musisz dostosować liczbę '..' poniżej do faktycznej głębokości\n",
    "        # notebooka względem katalogu CV-DEMO1.\n",
    "        # Jeśli 00_init_paths.py jest w 'CV-DEMO1/azure_databricks/notebooks/', to 2x '..'\n",
    "        # Jeśli 00_init_paths.py jest w 'CV-DEMO1/azure_databricks/common/notebooks/', to 3x '..'\n",
    "        current_working_dir = os.getcwd()\n",
    "        # Przyjmując, że jest w common/notebooks (jak pokazał Twój output):\n",
    "        project_root_path_fallback = os.path.abspath(os.path.join(current_working_dir, '..', '..', '..'))\n",
    "        calculated_project_root_path = project_root_path_fallback\n",
    "        print(f\"Obliczona ścieżka do korzenia projektu (fallback): {calculated_project_root_path}\")\n",
    "\n",
    "\n",
    "except NameError:\n",
    "    # Awaryjne rozwiązanie dla środowisk bez dbutils (np. lokalne testy)\n",
    "    print(\"Błąd: 'dbutils' nie znaleziono. Próba użycia os.getcwd().\")\n",
    "    current_working_dir = os.getcwd()\n",
    "    # Zakładamy, że os.getcwd() to .../azure_databricks/common/notebooks\n",
    "    # Potrzebujemy cofnąć się 3 razy do CV-DEMO1:\n",
    "    project_root_path_fallback = os.path.abspath(os.path.join(current_working_dir, '..', '..', '..'))\n",
    "    calculated_project_root_path = project_root_path_fallback\n",
    "    print(f\"Bieżący katalog notebooka (os.getcwd()): {current_working_dir}\")\n",
    "    print(f\"Obliczona ścieżka do korzenia projektu (fallback): {calculated_project_root_path}\")\n",
    "\n",
    "print(f\"Docelowa główna ścieżka repozytorium: {calculated_project_root_path}\")\n",
    "\n",
    "\n",
    "# --- Krok 2: Agresywne usuwanie WSZYSTKICH istniejących ścieżek z repozytorium ---\n",
    "# Usuwamy wszystko, co zawiera 'CV-DEMO1' (ignorując wielkość liter),\n",
    "# aby uniknąć konfliktów z automatem Databricks.\n",
    "paths_to_remove = []\n",
    "repo_identifier_lower = REPO_ROOT_DIR_NAME.lower()\n",
    "for p in list(sys.path): # Iteruj po kopii sys.path\n",
    "    if repo_identifier_lower in p.lower():\n",
    "        paths_to_remove.append(p)\n",
    "\n",
    "if paths_to_remove:\n",
    "    print(f\"\\nUsuwam {len(paths_to_remove)} istniejących ścieżek repozytorium z sys.path:\")\n",
    "    for p_remove in reversed(paths_to_remove): # Usuwaj od końca\n",
    "        if p_remove in sys.path:\n",
    "            sys.path.remove(p_remove)\n",
    "            print(f\"  Usunięto: {p_remove}\")\n",
    "else:\n",
    "    print(\"\\nBrak istniejących ścieżek repozytorium do usunięcia.\")\n",
    "\n",
    "\n",
    "# --- Krok 3: Dodanie DOKŁADNEJ ścieżki głównego katalogu repozytorium na sam początek sys.path ---\n",
    "# Zapewnia to, że nasza ścieżka ma najwyższy priorytet.\n",
    "if calculated_project_root_path not in sys.path:\n",
    "    sys.path.insert(0, calculated_project_root_path)\n",
    "    print(f\"\\nDodano '{calculated_project_root_path}' na początek sys.path.\")\n",
    "else:\n",
    "    print(f\"\\n'{calculated_project_root_path}' już istnieje na początku sys.path (nie dodano ponownie).\")\n",
    "\n",
    "\n",
    "# --- Krok 4: Opcjonalnie: Włącz autoreload (dla notebooków) ---\n",
    "try:\n",
    "    if 'autoreload' not in sys.modules:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "    get_ipython().run_line_magic('autoreload', '2')\n",
    "    print(\"Włączono autoreload dla modułów Pythona.\")\n",
    "except NameError:\n",
    "    print(\"Autoreload działa tylko w środowiskach IPython (np. Databricks Notebooks).\")\n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił błąd podczas włączania autoreload: {e}\")\n",
    "\n",
    "# --- Krok 5: Inicjalizacja SparkSession (opcjonalnie) ---\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "if 'spark' not in locals():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"CV Demo Project\") \\\n",
    "        .getOrCreate()\n",
    "    print(\"SparkSession zainicjalizowana.\")\n",
    "else:\n",
    "    print(\"SparkSession już istnieje.\")\n",
    "\n",
    "print(\"\\nKonfiguracja inicjalizacyjna zakończona.\")\n",
    "print(\"Aktualny sys.path po finalnej konfiguracji:\")\n",
    "for p in sys.path:\n",
    "    print(p)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
